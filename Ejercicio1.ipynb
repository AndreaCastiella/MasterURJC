{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reto 1\n",
    "\n",
    "## Ingeniería de características\n",
    "\n",
    "#### Miguel Ortiz y Andrea Castiella"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "FullSet_3 = pd.read_csv('../Reto1-Dataset/1000_tres.csv', header=None)\n",
    "FullSet_7 = pd.read_csv('../Reto1-Dataset/1000_siete.csv', header=None)\n",
    "\n",
    "# Reescalado a [0, 1]\n",
    "FullSet_3 = FullSet_3 / 255.0\n",
    "FullSet_7 = FullSet_7 / 255.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Función extracción de características"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "def feat_extraction(data):\n",
    "    num_feat = 4\n",
    "    features = np.zeros([data.shape[0], num_feat])\n",
    "    data = data.values.reshape([data.shape[0],28,28]) # Cada fila es una imagen, reshape a 28x28\n",
    "    \n",
    "    for i in range(data.shape[0]): # Por cada imagen \n",
    "        img = data[i,:,:]\n",
    "        # Característica 1\n",
    "        feat_1  = np.sum(img[:, :int(img.shape[1]/2)]) # Suma de los pixels la mitad izquierda de la imagen\n",
    "        features[i, 0] = feat_1\n",
    "        # Característica 2\n",
    "        feat_2 = np.sum(img[int(img.shape[0]/2):, :]) # Suma de los pixels de la mitad inferior de la imagen\n",
    "        features[i, 1] = feat_2\n",
    "        # Característica 3\n",
    "        feat_3 = np.sum(img[:, int(img.shape[1]/2):]) # Suma de los pixels de la mitad derecha de la imagen\n",
    "        features[i, 2] = feat_3\n",
    "        # Característica 4\n",
    "        feat_4 = np.sum(img[:int(img.shape[0]/2), :]) # Suma de los pixels de la mitad superior de la imagen\n",
    "        features[i, 3] = feat_4\n",
    "        \n",
    "    col_names = ['feat_1','feat_2', 'feat_3', 'feat_4']\n",
    "    return pd.DataFrame(features,columns = col_names)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utils functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def jitter(data, sigma=0.3):\n",
    "    #random_sign = (-1)**np.random.randint(1,3,*data.shape)\n",
    "    random_sign = (-1.)**np.random.randint(1,high=3,size=data.shape)\n",
    "    return data + np.random.normal(0,sigma,size=data.shape)*random_sign\n",
    "\n",
    "def single_stratified_split(X, Y, test_size=.2, random_state=1234):\n",
    "    # X is the dataframe with examples (rows) and attributes (columns)\n",
    "    # Y is the dataframe with labels\n",
    "    # test_size is the percentage of X separated; default is 0.2\n",
    "    # random_state is a seed for pseudorandom generation\n",
    "    # returns\n",
    "    #   X_train, Y_train = dataframes of (1-test_size)% of the X and Y\n",
    "    #   X_test, Y_test = dataframes of test_size% of the X and Y\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    split_ix = splitter.split(X,Y)\n",
    "    for train_ix, test_ix in split_ix:\n",
    "        X_train = X.loc[train_ix].reset_index(drop=True)\n",
    "        Y_train = Y.loc[train_ix].reset_index(drop=True)\n",
    "        X_test  = X.loc[test_ix].reset_index(drop=True)\n",
    "        Y_test  = Y.loc[test_ix].reset_index(drop=True)\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "def join_features_labels(X0, X1):\n",
    "    # X0, X1: dataframes\n",
    "    # returns a dataframe with X0 and X1 together and\n",
    "    #   a new column 'label'\n",
    "    #   = 0 for rows from X0\n",
    "    #   = 1 for rows from X1\n",
    "    #\n",
    "    Y0 = pd.DataFrame(np.zeros(X0.shape[0]),columns=['label'])\n",
    "    XY0 = pd.concat([X0,Y0],axis=1)\n",
    "    Y1 = pd.DataFrame(np.ones(X1.shape[0]),columns=['label'])\n",
    "    XY1 = pd.concat([X1,Y1],axis=1)\n",
    "    return pd.concat([XY0,XY1],axis=0,ignore_index=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "FullSet = join_features_labels(FullSet_3, FullSet_7)\n",
    "seed = 1234\n",
    "theta = 0.5\n",
    "X_full = feat_extraction( FullSet.drop('label', axis=1))\n",
    "Y_full = FullSet[['label']]\n",
    "test_size = 0.2\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
    "split_ix = splitter.split(X_full,Y_full)\n",
    "\n",
    "for train_ix, test_ix in split_ix:\n",
    "    X_train = X_full.loc[train_ix].reset_index(drop=True)\n",
    "    #Reordena los índices\n",
    "        #print(X_full.loc[train_ix])\n",
    "        #print(X_train)\n",
    "    Y_train = Y_full.loc[train_ix].reset_index(drop=True)\n",
    "    X_test  = X_full.loc[test_ix].reset_index(drop=True)\n",
    "    Y_test  = Y_full.loc[test_ix].reset_index(drop=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X_train)\n",
    "Y = Y_train.values.ravel() #Devuelve data como numpy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(jitter(X,sigma=0.01), jitter(Y,sigma=0.01),'x',alpha=0.1)\n",
    "plt.xlabel('data (x)'); plt.ylabel('label (y)')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "recta_regresion = LogisticRegression()\n",
    "recta_regresion.fit(X,Y)\n",
    "y_CDF = recta_regresion.predict_proba(X)\n",
    "print(y_CDF.shape)\n",
    "print(y_CDF)\n",
    "y_pred = y_CDF[:,1]\n",
    "\n",
    "plt.plot(jitter(X,sigma=0.01), jitter(Y,sigma=0.01),'x',alpha=0.1)\n",
    "plt.plot(X,y_pred,'.r')\n",
    "plt.xlabel('data (x)'); plt.ylabel('label (y)')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Discriminant Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "theta = 0.8 #<-- paramter of the discriminant function\n",
    "\n",
    "ix_1 = y_pred < theta\n",
    "ix_0 = ~ix_1\n",
    "plt.plot( jitter(X[ix_1],sigma=0.01), \\\n",
    "          jitter(Y[ix_1],sigma=0.01), \\\n",
    "          'bx',alpha=0.1)\n",
    "plt.plot( jitter(X[ix_0],sigma=0.01), \\\n",
    "          jitter(Y[ix_0],sigma=0.01), \\\n",
    "          'yo',alpha=0.1)\n",
    "plt.text(0,theta, r'$ \\theta $')\n",
    "plt.plot(X,y_pred,'.r')\n",
    "plt.plot([0.05,1],[theta,theta],'m:')\n",
    "plt.xlabel('data (x)'); plt.ylabel('label (y)')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-env",
   "language": "python",
   "name": "master-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}